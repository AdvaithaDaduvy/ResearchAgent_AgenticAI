applied
sciences
Article

Brain Tumor Analysis Using Deep Learning and VGG-16
Ensembling Learning Approaches
Ayesha Younis 1 , Li Qiang 1, *, Charles Okanda Nyatega 2,3 , Mohammed Jajere Adamu 1
and Halima Bello Kawuwa 4
1

2

3

4

*

Citation: Younis, A.; Qiang, L.;
Nyatega, C.O.; Adamu, M.J.;
Kawuwa, H.B. Brain Tumor Analysis
Using Deep Learning and VGG-16
Ensembling Learning Approaches.
Appl. Sci. 2022, 12, 7282. https://
doi.org/10.3390/app12147282
Academic Editor: Jan Egger
Received: 7 June 2022
Accepted: 17 July 2022
Published: 20 July 2022
Publisher s Note: MDPI stays neutral
with regard to jurisdictional claims in

School of Microelectronics, Tianjin University, Tianjin 300072, China; ayesha@tju.edu.cn (A.Y.);
mainajajere@tju.edu.cn (M.J.A.)
School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China;
ncharlz@tju.edu.cn
Department of Electronics and Telecommunication Engineering, Mbeya University of Science and Technology,
Mbeya P.O. Box 131, Tanzania
School of Precision Instrument and Opto-Electronics Engineering, Tianjin University, Tianjin 300072, China;
halima@tju.edu.cn
Correspondence: liqiang@tju.edu.cn

Abstract: A brain tumor is a distorted tissue wherein cells replicate rapidly and indefinitely, with
no control over tumor growth. Deep learning has been argued to have the potential to overcome
the challenges associated with detecting and intervening in brain tumors. It is well established
that the segmentation method can be used to remove abnormal tumor regions from the brain, as
this is one of the advanced technological classification and detection tools. In the case of brain
tumors, early disease detection can be achieved effectively using reliable advanced A.I. and Neural
Network classification algorithms. This study aimed to critically analyze the proposed literature
solutions, use the Visual Geometry Group (VGG 16) for discovering brain tumors, implement a
convolutional neural network (CNN) model framework, and set parameters to train the model for
this challenge. VGG is used as one of the highest-performing CNN models because of its simplicity.
Furthermore, the study developed an effective approach to detect brain tumors using MRI to aid
in making quick, efficient, and precise decisions. Faster CNN used the VGG 16 architecture as a
primary network to generate convolutional feature maps, then classified these to yield tumor region
suggestions. The prediction accuracy was used to assess performance. Our suggested methodology
was evaluated on a dataset for brain tumor diagnosis using MR images comprising 253 MRI brain
images, with 155 showing tumors. Our approach could identify brain tumors in MR images. In the
testing data, the algorithm outperformed the current conventional approaches for detecting brain
tumors (Precision = 96%, 98.15%, 98.41% and F1-score = 91.78%, 92.6% and 91.29% respectively) and
achieved an excellent accuracy of CNN 96%, VGG 16 98.5% and Ensemble Model 98.14%. The study
also presents future recommendations regarding the proposed research work.
Keywords: brain tumor; Artificial Intelligence (AI); deep learning; convolutional neural network
(CNN); feature extraction

published maps and institutional affiliations.

1. Introduction
Copyright:   2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).

The application of information technology and machine learning in medicine has
gained importance in today s world. Artificial intelligence is a scientific field concerned
with developing a machine that can learn on its own without human intervention to prepare
itself for dealing with potential cases on its own. Application of this science finds high
relevance in developing interventions for brain tumors, as the tumor cells show highly
uncertain behavior that is too complex to be controlled through conventional medicine.
Once tumor cells are generated within the human brain, the likelihood of serious
fatalities is created. Due to the complexity of issues, brain tumors are extremely unstable

Appl. Sci. 2022, 12, 7282. https://doi.org/10.3390/app12147282

https://www.mdpi.com/journal/applsci

Appl. Sci. 2022, 12, 7282

2 of 20

and potentially fatal in the absence of intelligent solutions [1]. Formation of tumor takes
place in the brain during the early stages and can later spread gradually to other elements
of the body. To deal with such complex issues, humans can create machines behaving like
living beings, capable of learning from experience and applying their experience to cater to
the emerging issues due to the accumulation of tumor cells in the brain [2]. In this regard,
in the field of medical imaging, AI and digital image processing a huge impact is made by
convolutional neural network (CNN) [3].
Some tumors can cause damage to surrounding structures in the brain. So, before
performing any brain surgical technique or therapeutic intervention, doctors must specify
the exact affected region or area in the brain. Brain tumor segmentation is a process of
separating tumors by isolating better and healthier tissues from affected areas. As a result,
brain segmentation is the most challenging task in diagnostic techniques. Instead of being
specialized in the brain tumor domain, many exclusionary techniques depend on general
edge-based data. Due to their efficacy in detecting features of images, deep learning
algorithms have lately been used for tumor segmentation tasks [4,5].
A positive brain tumor diagnosis is critical for enhancing treatment outcomes and
patients  lives. Radiologists must diagnose brain tumors as early as possible. According to
Amin et al. [6], a typical brain tumor can double in size within just twenty-five days. If the
person is not treated correctly, the person s survival rate is typically less than 12 months [7].
Keeping the severity of the problem in mind, a fully automated method for detecting
brain tumors is required. The manual process of evaluating many images obtained in a
clinic is complicated and insufficient to understand the behavior of different tumors. In
order to understand and intervene in this complex phenomenon, more precise computerbased tumor detection/diagnosis technologies are required. Several endeavors have been
undertaken to investigate machine learning techniques for digitizing this procedure in
recent times. Deep learning methods have recently sparked an interest in more accurate
and consistent detection of tumor cells.
Automatic defect recognition in medical imaging has emerged as a promising field for
various medical diagnostic procedures. The detection and tracking of tumors in Magnetic
Resonance Imaging (MRI) is crucial because it offers details about abnormal tissues needed
for therapeutic interventions. MRI brain tumor detection is a complicated task, due to
the complexities and diverse forms of tumors. Collecting, organizing, and analyzing
medical images has become digitized in today s digital realm [8]. Even with cutting-edge
technology, thorough interpretation of medical images poses time and accuracy problems.
The difficulty is particularly acute in abnormal color and shape areas that radiologists
must recognize for future research. There is room in current literature and practice to
reap the potential of CNN for image analysis techniques required in brain tumor detection
and diagnosis [3]. Considering the demand for advanced machine learning, this research
intends to implement the CNN model in light of the current state of knowledge and propose
the training of data to handle the complexities arising in detecting brain tumors while
offering interventions.
1.1. Deep Learning Algorithms (DLAs)
Deep Learning Algorithms (DLAs) are based on a type of AI and machine learning
through which imitation of the way humans acquire knowledge is done [9]. When the
developments in brain MRI and respective computer interventions are examined, central
importance is given to Convolutional Neural Networks (CNNs) and Deep learning (DL).
Conventional neural networks have already progressed or advanced into Deep Neural
Network (DNN) approaches. Connections in these networks are data-driven, and the type
of methodology is automatically generated without any intervention, which accounts for
the precision and impressive performance of these systems in a variety of areas. In reality,
it is a deep learning algorithm composed of several nerve-based algorithms that automatically detect features and characteristics in input data before applying the knowledge for
developing interventions [9].

Appl. Sci. 2022, 12, 7282

accounts for the precision and impressive performance of these systems in a variety of
areas. In reality, it is a deep learning algorithm composed of several nerve-based
algorithms that automatically detect features and characteristics in input data before
3 of 20
applying the knowledge for developing interventions [9].
1.1.1. Convolutional Neural Network (CNN)
1.1.1. AI s
Convolutional
Neural
potential to
bridgeNetwork
the gap(CNN)
between human and machine abilities has grown
considerably.
To
generate
outstanding
results,human
both scientists
and enthusiasts
on
AI s potential to bridge the gap between
and machine
abilities hasfocus
grown
several
subject
aspects.
The
primary
concern
of
this
approach
is
to
take
control
over
the
considerably. To generate outstanding results, both scientists and enthusiasts focus on
machinesubject
and toaspects.
interpretThe
theprimary
world the
same of
way
that
humansisdo,
but then
useover
that
several
concern
this
approach
to take
control
understanding
fortoa multitude
of jobs,
likethe
image
processing
computer
vision,
image
the
machine and
interpret the
world
same
way thatand
humans
do, but
then
use
processing
and categorization,
mainstream
entertainment,
expert
language
that
understanding
for a multitude
of jobs,press
like image
processing
andsystems,
computer
vision,
processing,
and soand
on. Advancements
computer vision
have been builtexpert
and developed,
image
processing
categorization, in
mainstream
press entertainment,
systems,
most noticeably
through
frameworkinknown
as CNN.
a DL
process
language
processing,
and asostructured
on. Advancements
computer
visionCNN
have is
been
built
and
that
requires
and
prioritizes
multiple
elements
in
an
image,
enabling
them
to
developed, most noticeably through a structured framework known as CNN. CNN isbe
a
differentiated
from
one another.
A ConvNet
takeselements
considerably
pre-processing
than
DL
process that
requires
and prioritizes
multiple
in anless
image,
enabling them
to
be differentiated
one another.
ConvNet
takes methods
considerably
other
classification from
techniques.
WhileAsimple
filtering
are less
also pre-processing
effective, with
than
othertraining,
classification
While simple
filtering [10].
methods are also effective, with
adequate
they techniques.
can learn extensions
as ConvNet
adequate
training,
they can
extensions
as ConvNet
[10].
Individual
features
in alearn
convolution
layer
are known
as neurons, and the output of a
Individual
features
inpixels
a convolution
layer
known asisneurons,
andof
thepixel
output
of a
neuron
is defined
by the
around it.
Theare
perceptron
the region
density
neuron
is
defined
by
the
pixels
around
it.
The
perceptron
is
the
region
of
pixel
density
that
that can influence a neuron s response [11,12]. A neuron s computing efficiency increases
can
influence
neuron s
response
[11,12].inAthe
neuron s
efficiency
increases
the
as the
amounta of
convolution
operation
designcomputing
increases. Layers
dividing
theas
CNN
amount
of convolution
operation
the designinput,
increases.
Layers
dividing
the CNNaspects,
have a
have a hierarchical
system.
CNNincomprises
hidden
units,
convolutional
hierarchical
system.
CNN comprises
input, hiddenand
units,
convolutional
aspects,
so on.
and so on. It
also includes
batch normalization
convolution
layers.
CNNand
differs
in
Itproportion
also includes
batch
normalization
convolution the
layers.
CNN
in proportion
to
to the
number
of layersand
implemented,
size,
anddiffers
the type
of activation
the
number
of layers
size, and the
type of activation
methods used.
CNN
methods
used.
CNNimplemented,
variables aretheempirically
determined
and empirically
supported
variables
are
empirically
determined
and
empirically
supported
through
trial-and-error.
through trial-and-error. Neurons only react to changes in a part of the area of visuals
Neurons
only
react
to changes
in aIfpart
of the
areaintersect,
of visuals
referred
to ascover
the Receptive
referred to
as the
Receptive
Field.
similar
fields
then
they will
the entire
Field.
If
similar
fields
intersect,
then
they
will
cover
the
entire
visible
region.
1
visible region. Figure 1 presents the structure of a single layer ConvolutionalFigure
Neural
presents
the structure of a single layer Convolutional Neural Network.
Network.

Figure1.
1. Single
Single Layer
Layer Convolutional
ConvolutionalNeural
NeuralNetwork.
Network.
Figure

1.1.2.
1.1.2. VGG
VGG 16
16
VGG
16
VGG 16 is
is aa model
model for
for aa 16-layer
16-layer CNN
CNN model.
model. It
It is
is still
still considered
considered one
one of
of today s
today s best
best
and
most
effective
models.
Instead
of
having
numerous
parameters,
the
VGG
and most effective models. Instead of having numerous parameters, the VGG 16
16 model
model
architecture
  3 kernel
kernel size.
size. The
The significance
architecture focuses
focuses on
onConvNet
ConvNetlayers
layerswith
witha a3 3 3
significance of
of this
this
model
lies
in
the
fact
that
its
values
are
freely
available
online
and
may
be
downloaded
model lies in the fact that its values are freely available online and may be downloaded
for
one s
systems
and applications.
WhenWhen
compared
to othertodeveloped
comprefor use
usein in
one s
systems
and applications.
compared
other developed
hensives, it is noted for its simplicity. This model s minimum expected input image size
is 224   224 pixels with three channels. In neural networks, optimization algorithms are
used to evaluate whether a neuron must be engaged or not, by determining the weighted
sum of input. The need for kernel function arises from inducing non-linearity into the
output neuron. A neural network s neurons function together with weight, bias, and the
related training procedure. The neurons  link weights are adjusted based on the output
inaccuracy. The input layer and the activation function add non-linearity to artificial neural

Appl. Sci. 2022, 12, 7282

comprehensives, it is noted for its simplicity. This model s minimum expected input
image size is 224 224 pixels with three channels. In neural networks, optimization
algorithms are used to evaluate whether a neuron must be engaged or not, by determining
the weighted sum of input. The need for kernel function arises from inducing nonof 20
linearity into the output neuron. A neural network s neurons function together 4with
weight, bias, and the related training procedure. The neurons  link weights are adjusted
based on the output inaccuracy. The input layer and the activation function add noninput,
allowing
it to learn
accomplish
tasks.
2 presents
a standard
linearity
to artificial
neuraland
input,
allowingcomplex
it to learn
andFigure
accomplish
complex
tasks.
VGG
162network
Figure
presentsarchitecture.
a standard VGG 16 network architecture.

Figure 2.
2. A
A Standard
Standard VGG
VGG 16
16 Network
Network Architecture.
Architecture.
Figure

1.1.3.
1.1.3. Ensemble
Ensemble Model
Model
For
many
machine-learning
Ensemble modeling
modeling emerges
emerges as
as aa state-ofstate-ofFor many machine-learning challenges,
challenges, Ensemble
the-art
solution,
as
it
aggregates
the
predicting
capacities
of
multiple
models
such
the-art solution, as it aggregates the predicting capacities of multiple models such that
that
higher
higher performance
performance can
can be
be achieved.
achieved. Different
Different training
training data
data sets
sets or
or modeling
modeling techniques
techniques
are
are utilized
utilized together
together in
in Ensemble
Ensemble modeling
modeling which
which further
further integrates
integrates the
the forecasts
forecasts of
of each
each
base
model,
to
give
out
a
single
predictive
performance
for
the
unknown
data.
The
use
base model, to give out a single predictive performance for the unknown data. The use of
of
ensemble
diminish
forecast
generalization
capability.
With With
multiple
modensemblemodels
modelsintends
intendstoto
diminish
forecast
generalization
capability.
multiple
els,
the prediction
error decreases
as long as
are models
diversified
independent.
models,
the prediction
error decreases
asbase
longmodels
as base
areand
diversified
and
Deep
Learning
Synthesis
seeks
to
improve
efficiency
by
merging
features
from
independent. Deep Learning Synthesis seeks to improve efficiency by mergingdifferent
features
models
into a unique
feature.
In addition,
learning
can be
classified
from different
modelspredicted
into a unique
predicted
feature.ensemble
In addition,
ensemble
learning
can
into
data
ensembles,
and
classifiers
depend
on
the
scale
of
integration.
Since
the
feature
set
be classified into data ensembles, and classifiers depend on the scale of integration. Since
includes more data about the MRI images than all classifiers combined, incorporation at
the feature set includes more data about the MRI images than all classifiers combined,
this level is expected to improve classification performance. The classifier ensemble consists
incorporation at this level is expected to improve classification performance. The classifier
of classifier output sets, wherein voting methods determine output. In contrast, a features
ensemble consists of classifier output sets, wherein voting methods determine output. In
ensemble consists of extracted features given for the classification for the final result.
contrast, a features ensemble consists of extracted features given for the classification for
In these models, the probabilities are estimated by beginning an active contour and
the final result.
executing it until a likelihood smaller than the stated threshold is detected, to give out
In these models, the probabilities are estimated by beginning an active contour and
an indication of the tumor area [13,14]. As matching a big tumor area to an image is a
executing it until a likelihood smaller than the stated threshold is detected, to give out an
complex process, some algorithms in literature have included atlas registration, in contrast
indication of the tumor area [13,14]. As matching a big tumor area to an image is a complex
to tumor segmentation [15]. The specified critical values of the proposed model would
process, some algorithms in literature have included atlas registration, in contrast to
imply that it successfully located the primary tumor region while avoiding false positives.
tumor segmentation [15]. The specified critical values of the proposed model would imply
Most existing practices refer to the entire tumor site, which results in low core performance
that it successfully
located
the primary
tumor
region
while avoiding
false
positives.ofMost
metrics
and attempts
to improve
regions.
These
limitations
stress the
importance
the
existing
practices
refer
to
the
entire
tumor
site,
which
results
in
low
core
performance
traditional architecture proposed in this work. In the research, methods contain
both
metrics and attempts
to improve
regions.
limitations
stresscan
theform
importance
of the
computational
and scientific
processes
[16].These
Tumors,
by definition,
in any spatial
traditional
architecture
proposed
in
this
work.
In
the
research,
methods
contain
both
location in the brain and have a unique and irregular structure, making automated methods
computational
and scientific
processes
[16].
Tumors,
bystrategies
definition,were
can tested
form inonany
spatial
challenging
to detect.
Due to the
fact that
most
previous
manually
location
in
the
brain
and
have
a
unique
and
irregular
structure,
making
automated
produced datasets, generality cannot be assured. The brain tumor diagnosis computation
and computer-assisted therapy society gathers, disseminates, or establishes MRI image
datasets, comprising glaucoma tumor MRI scans [17,18].
In this study, researchers investigated and examined the effectiveness of two machine
learning techniques, CNN and Bi-LSTM. In addition, the study proposed using ML techniques to overcome the shortcomings of classical approaches. Since these ML algorithms
have been shown to perform effectively in most pattern categorization problems, they are
helpful as neural networks can learn to produce intricate mappings between input and

Appl. Sci. 2022, 12, 7282

on manually produced datasets, generality cannot be assured. The brain tumor diagnosis
computation and computer-assisted therapy society gathers, disseminates, or establishes
MRI image datasets, comprising glaucoma tumor MRI scans [17,18].
In this study, researchers investigated and examined the effectiveness of two
machine learning techniques, CNN and Bi-LSTM. In addition, the study proposed using
20
ML techniques to overcome the shortcomings of classical approaches. Since these5 ofML
algorithms have been shown to perform effectively in most pattern categorization
problems, they are helpful as neural networks can learn to produce intricate mappings
betweenThey
input
and
output.
handle
far more difficult
classification
andthan
detection
output.
can
handle
far They
more can
difficult
classification
and detection
problems
those
problems
than
those
at
hand.
at hand.
In aa nutshell,
nutshell, the
the CNN
CNN results
results on
on the
the data
data are
are used
used to
to get
get an
an optimal
optimal classification
classification
In
approachofofimproving
improving
the previously
proposed
methodologies.
A deepalgorithm
learning
approach
the previously
proposed
methodologies.
A deep learning
algorithm would
(Bi-LSTM)
would
be usedfeatures.
to extract
features.
Themethod
clustering
method
used and
(Bi-LSTM)
be used
to extract
The
clustering
is used
andisapplied
to
to a data The
collection.
results
would
assess theofefficiency
of the recommended
aapplied
data collection.
resultsThe
would
assess
the efficiency
the recommended
technique.
technique.
Using the
feature
CNN
leadpicture
to higher
picture classification
Using
the feature
before
CNNbefore
can lead
to can
higher
classification
results, andresults,
using
and usingwould
Bi-LSTM
wouldnetwork
increase accuracy.
network accuracy.
3 presents
the architecture
Bi-LSTM
increase
Figure 3Figure
presents
the architecture
of the
of the ensemble
ensemble
model.model.

Figure 3.
3. Architecture
Architecture of
of Ensemble
Ensemble Model.
Model.
Figure

1.2.
1.2. Research
Research Objectives
Objectives
The
The proposed
proposed technique
technique for
for identifying
identifying and
and classifying
classifying tumors
tumors from
from brain
brain scans
scans and
and
images
CNNand
andDL
DLtechniques.
techniques.
These
networks
constructed
neurons
images used CNN
These
networks
are are
constructed
fromfrom
neurons
with
with
learnable
weights
biases.
proposed
studyaimed
aimedtotocritically
critically analyze
analyze how
learnable
weights
and and
biases.
TheThe
proposed
study
how
researchers
solved
brain
tumor
issues
in
previous
literature
by
using
Visual
Geometry
researchers solved brain tumor issues in previous literature by using Visual Geometry
Group
Group (VGG
(VGG 16)
16) to
to discover
discover aa brain
brain tumor,
tumor, implement
implement aa CNN
CNN model
model framework,
framework, and
and set
set
parameters
to
train
the
model
for
this
challenge.
VGG
was
used
as
one
of
the
highestparameters to train the model for this challenge. VGG was used as one of the highestperforming
models because
becauseof
ofits
itssimplicity.
simplicity.Furthermore,
Furthermore,
study
developed
performing CNN
CNN models
thethe
study
developed
an
an
effective
approach
for detecting
tumors
Magnetic
Resonance
effective
approach
for detecting
brainbrain
tumors
using using
Magnetic
Resonance
ImagingImaging
(M.R.I.)
(M.R.I.)
scans
for detection
tumor detection
in making
efficient,
and precise
decisions,
scans for
tumor
to aid to
in aid
making
quick,quick,
efficient,
and precise
decisions,
and
and
conducted
segmentation
of
the
data
sources
we
intended
to
use
in
the
proposed
conducted segmentation of the data sources we intended to use in the proposed research
research
work. work.
1.3. Strength and Novelty in Proposed Model
1.3. Strength and Novelty in Proposed Model
The novelty of the study is a unique solution being proposed by the researchers that
The novelty of the study is a unique solution being proposed by the researchers that
can assist with the detection of brain tumors in the acquired MRI image, offering great
can assist with the detection of brain tumors in the acquired MRI image, offering great
precision. The proposed model deploys a technique that intends to offer training for models
precision. The proposed model deploys a technique that intends to offer training for
with higher optimization compared to previous techniques in the literature [19 28].
models
with
higher optimization
to previous
in the
literature
[19 
High
optimization
of training compared
would reduce
requiredtechniques
computational
power,
marking
28].
our model s significance for practitioners and researchers. The study model comprised a
High optimization
of training
would reduce
required
marking
combination
of deep learning
and transfer
learning
models computational
to facilitate thepower,
achievement
of
our
model s
significance
for
practitioners
and
researchers.
The
study
model
comprised
a
a remarkable accuracy rate that would exceed the performance of other available solutions.
2. Literature Review
A group of irregular brain cells make a brain tumor. Ambiguous development in the
synapses characterizes brain tumors. The high rigidness and inflexibility of the skull makes
it problematic to contain potential expansion in volume. The impact may be experienced
in the form of interference with human capacities along with swelling in to other body
parts [29]. Over 130 different brain, and central nervous, cancers range from benign to
malignant, exceedingly rare to reasonably common [29]. However, each of the 130 brain
tumors is classified as either primary or secondary. Moreover, the preponderance of brain

Appl. Sci. 2022, 12, 7282

6 of 20

malignancies are secondary brain tumors [30]. Breast, stomach, or skin cancer begins in
another portion of the anatomy and progresses to the brain.
In literature, machine learning, deep learning in particular, has been argued to have
the potential of overcoming the challenges associated with the detection and intervention
of brain tumor [31]. Deep Learning is regarded as one of the best methods in data science
and artificial intelligence to train models through data to develop valuable decision-making
abilities [32]. Obtaining the predicted network by reducing the image without sacrificing
the information required to make predictions is sought in such models. Segmentation
of tumor is known to be best performed by deep learning techniques, making it a viable
choice for implementation [33].
Deep Learning [9], which resembles the tasks of the human brain, is one of the
operations of Artificial Intelligence. It is being used to detect computational artifacts,
recognize the voice, translate language skills, and make decisions. It may comprehend
without human management, demonstrated by unorganized and unlabeled data. CNNs
are deep neural networks, often utilized in deep learning visual depiction analysis [15].
The rest of this section is dedicated to exploration of current literature for application of
deep learning in medical diagnosis.
Viewing the current literature, one cannot deny that Computed Tomography (CT)
brain scanning is one of the most common applications of deep learning, with learning
algorithms producing the most accurate results [34]. Current research introduces new
connectivity supervised learning, LM for deep CNN topologies that combine (CNN) and
classic architectures. The implicit condone neural network assists CNN in identifying
the optimum files for aggregate and convolution. As a result, the primary neurological
classification algorithm [35] learns faster and more efficiently. In current study, researchers
used brain MRI images from the Kaggle portal [36], created for brain tumor categorization
research. The collection comprises 138 images of people who are perfectly well and 200
scans of sick people. Images come in a variety of sizes and formats.
In the study of Marcin Woz niak, Jakub Si ka and Micha  Wieczorek [37], a DL-based supervised technique for detecting changes in synthetic aperture (SAR) images was proposed.
This method generated a suitable volume of DBN data using MRI images employing a
segmentation technique. This method s detecting performance suggests the applicability of
deep learning-based approaches for handling change identification problems. Moreover,
the study describes an automated brain tumor classification system based on DNN [38].
The suggested networks are intended to be used in images of glioblastoma illness. A new
convolution layer is proposed in current research and the suggested cascade design uses
the results of a core CNN as an incidental finding for the following CNN.
Categorizing glioma tumor imaging can be incredibly useful in computer-aided diagnostics (CADs); however, it is a time-consuming process. Each MRI has 150 220 brain
tumor images produced at healthcare centers, and regularly grows. Doctors assess a tumor
individual using approximate value and instinct, threatening the patient s life [39].
A machine learning-based technique for segmenting brain tumors using several MRI
modes is provided in this paper. The suggested hybrid CNN architecture predicts output
labels using a patch-based method that considers local and factual data [40]. The proposed
network handles the over-fitting problem by combining dropout regularization with the
compound considered, while a two-phase training technique addresses the issue of the
varying definition. The proposed method incorporates a pre-stage in which images are
normalized, and the bias field is modified, a CNN feed-forward run, and the elimination
of results encompassing the skull region. The research methodology is validated using
the BRATS 2013 data, yielding dice scores, sensitivities scores, and specificity scores of
approximately 0.86, 0.86, and 0.91, respectively.
MRI is perhaps the most often used method for imaging brain regions. Since MRI
moderates tissue differences, it is the most versatile imaging method for simulating brain
regions of interest, such as tumors [41,42]. The primary purpose of tumor segmentation
is to identify and exact the segmentation of metastatic tumor voxels, like edema, necrotic

Appl. Sci. 2022, 12, 7282

7 of 20

centers, and tumorous tissues. DL techniques develop standard NN by including hidden layers to the network structure between output units to reflect more complex and
nonlinear connections.
Although the network model does not need feature extraction to apply a small amount,
training CNN architecture is complex and difficult since it needs a dataset for testing and
training before the structure is ready for classification, which is not always available. In addition, hardware is required for computing the massive factor for large image sizes [43,44].
The proposed approach for detecting brain cancers is based on deep learning, and
brain magnetic resonance is used for tumor evaluation using automated classification
methods. For image improvement, triangular fuzzy median filtering is used, which aids in
reliability, such as for the unsupervised fuzzy set approach [45,46]. Gabor characteristics
are extracted from each individual s lesions, and similar texture (ST) features are derived.
These ST traits are fed into transfer learning (ELM), including one for tumor categorization.
The proposed strategy produces better results while consuming less processing time. The
suggested system of the current study is divided into three sections: augmentation, image
pre-processing, and Convolutional Neural Networks (CNNs). The strategy suggests a
methodology that uses an asset and a deep learning algorithm. The CNN has an 87.42%
accuracy percentage with minimal difficulties involved, distinguishing it from all other
strategies [47].
The hidden layers differentiate CNN models. Two convolution layers use termination criteria and batch normalization for regularization in addition to the dropout layer.
Without such layers, the other two models are used. For training, the BRATS 2013 Dataset
was used, while for testing, the World Brain Atlas was used (WBA). According to the
data, model 4 provides a satisfactory false alarm rate for non-tumor images, whereas
model 6 provides the desired results and achieves 96% accuracy [48]. Since DL Algorithms
can effectively express complex interactions without needing a wide variety of equipment, they are a remarkable development in ML (KNN) [49,50]. As a result, they evolved
swiftly to become the cutting-edge in several health informatics fields, such as informatics,
healthcare analytics, and pattern classification.
3. Comparative Analysis
The research needed to look into the most recent cutting-edge studies on brain tumor
identification and tracking. This study evaluated recent papers published in the last decade
or so that focused on the identification and categorization/classification of brain tumors
employing CNN and VGG 16 algorithms.
Existing Methodology
Current framework systems follow multiple pre-defined procedures to identify brain
MRI images [51 54]. The effective mechanisms involved in recognizing and classifying
tumor and non-tumor units in MRI brain imaging is covered in [55,56]. The following is a
brief overview of prospective approaches and strategies. Most images to be entered as input
are MRI brain scans [57,58]. Depending on the architecture and memory limitations, the
input might be 2D or 3D. Due to its efficiency in significantly enhancing image data the input
regarding images to be entered has proved to be as crucial as any other stage [19 21,59].
Segmentation primarily divides the input image into identical sections depending
upon specified criteria, allowing only essential data to be extracted and the remainder to
be discarded [22,23]. There are numerous approaches. Some studies segment the actual
tumor [48], whereas others segment the image region including the tumor [25]. The goal
of the classification stage is to divide the input data into various categories based on
comparable behavior patterns inside the group.
The third process described in the literature involves directly feeding brain MRI
images to a Deep Learning program for categorization with no pre-processing. Statistical
techniques or machine learning techniques are used to identify features. The Deep Learning
algorithm is then trained using these extracted features. While deep learning methods do

Appl. Sci. 2022, 12, 7282

8 of 20

not necessitate extraction of features, the study has shown that extracted features using
machine learning, or meta-heuristic optimization methods, are still used in different models
with reinforcement learning to include efficient and resilient features [27].
Each plan s principal purpose is to change the levels of Supervised Learning based
on the experimental criteria and then choose the model with the best performance. Using
machine and Deep Learning approaches, researchers employed models to build efficient
systems. The dataset is divided into learning, testing, and verification sets before beginning any of the approaches above. Convolutional Neural Network (CNN) has received
substantial appreciation and recognition in Deep Learning for its ability to automatically
extract and detect deep features by responding to tiny changes in images.
A constant comparative table (Table 1) briefly describes all of the essential characteristics of each previously presented study paper in this area. Table 1 essentially provides a
concise overview of the tactics employed up to this moment. Some limits and inadequacies,
as well as the obtained results, have been highlighted for thorough analysis.
Table 1. Comparative Analysis.
Ref.

Year

Methodology/
Approach

Dataset

Result

Drawback

[60]

2020

CNN

Fig-share Total
Images (3064)
from 233 patients)

87% and 92%

No training time has
been mentioned

[51]

2019

PNN
Classification CNN

KaggleTCIA

90% Accuracy

Lack of comparative analysis

[52]

2019

R-CNN And SVM

Pvt Dataset

95% Accuracy

Rapid conversion
convolutional
feature map into the
region proposed

[53]

2020

Inception Pre-trained
CNN

BRATS
13,14,17,18

92% Classification

Complex approach

[54]

2019

ResNet-50 for Detection
GAN for Data Augmentation

BRATS 2016

ResNet87% accuracy
With GAN, 92%

Certain major aspects are
not mentioned

[55]

2019

CNN

A private dataset
comprising 330 images

Accuracy 98%
with low Complexity level

Lower-level data
implementation.

[56]

2019

CNN

Fig-share
dataset
(3064 images)

96%
Accuracy

Lacking comparative analysis

Ambiguous results and no
exceptions carried out

[57]

2019

3D-Multi CNNs

BRATS 2018

Coefficient
84%
Sensitivity
82%
Specificity 99%

[61]

2019

Alexnet,
VGG-16

BRATS
2015

VGG16
gives 98%
accuracy

There is no information about
enhancement other
than normalization.

[56]

2016

D.N.N.
and
ELM

1000
Images private
Dataset f om some
Indian hospital

D.N.N. showed
88% accuracy
E.L.M.
Delivered 96% Accuracy

Complex features
extraction process

[59]

2017

Convnet and slicenet
and VGNet

BRATS 2017
And TCIA

97% Accuracy
being achieved

Scheme + high
training time

BRATS
2015

75.4% for
Flair 1.3%
improvement 74.2%
with 3.3%
improvement

Limited data on studies
previously done

[19]

2017

3D CNN

Appl. Sci. 2022, 12, 7282

9 of 20

Table 1. Cont.
Ref.

Year

Methodology/
Approach

Dataset

Result

Drawback

[20]

2018

Classification D.N.N. and
Segmentation Using Fuzzy C

Harvard
Dataset (66 M.R.I.s with 22
and 44 standard images
vs. affected.

98%

The methodology used was
not novel.

[21]

2018

CNN for Classification
CNN for grading

data sets
Fig-share 3064
and REMBRA
NDT 516 images)

Accuracy of 96% and 98%

High learning rate

[22]

2020

BRAIN NETs
For detect
And Classification

(BITE), Fig share
(4689 detection
and for classification)

98% accuracy
For detection
and 99%

Complex architecture

[23]

2020

BRATS,
CE-MRI

VGGnetAnd
KNN as classifier

97.28% and
98.69% on
Both of the datasets

No
training
testing time,

[24]

2020

R.N.N.

Private
dataset
comprising 1000 images

Classification 96% Specificity
98%
Sensitivity 97%

There was no specific place.
This process is examined.

[25]

2019

CNN

Kaggle

Accuracy
92.3%

Basic model

[26]

2020

ELMLRF
CNN

Figshare dataset
(3064 images)

97%

Small training data.

[27]

2020

CNN

Kaggle

90 to 99% Accuracy

No preprocessing data

[28]

2019

Residual
Network
ResNet

Fig-share
(3064 images)

95% Accuracy being achieved

Ambiguous data depiction

Proposed
Model

2022

CNN, VGG-16,
Ensemble Model

MRI dataset

96%, 98.15%, 98.41%

High accuracy

Similarly, no efficiency statistic constitutes a universal standard for all studies. The
researchers used a set of performance assessments, but the interpretations and mathematical
depiction of performance indicators in Table 1, and the findings in Table 1, were decisive.
They are all related to the accuracy of parameter estimates in some way. When it comes to
detection, excellent accuracy and performance are essential.
As a result, it was found that the critical concern of the specialists remained accuracy.
However, we know that MRI scans have an imbalanced class issue, so that that accuracy
would not help much. Various ML techniques are available that can improve model performance despite imbalanced data, such as focal loss techniques, SMOTE (Synthetic Minority
Over-sampling Technique), and class-weight [62]. When there is a class discrepancy, precision, and recall work well. The majority of the research used these in combination with
accuracy. Precision ensures correctness, while recall indicates if the minority class, or the
values that guide, were covered. In this perspective, both indicators are equally important
in terms of accuracy.
4. Proposed Research Methodology
The study aimed to automate the detection of brain tumors in MRI brain scans. Our
suggested strategy uses CNN and VGG 16 to detect brain tumors employing brain MRI
data. According to Devi [63], VGG 16 can be considered a contender for other optimization
methods, such as AlexNet and Grid Search optimization, while detecting and classifying
brain tumor MRI with CNN. Considering the rationale of [63,64] for the application of
AI in diagnostics, the proposed framework was broken down into many steps. The brain
MRI image was used as the primary input image. Data operations, including thresholding
and refractive error, were carried out to reduce noise. The database of brain MRI images
was analyzed and improved. The images were then resized for use as input to the model.

Appl. Sci. 2022, 12, 7282

suggested strategy uses CNN and VGG 16 to detect brain tumors employing brain MRI
data. According to Devi [63], VGG 16 can be considered a contender for other optimization
methods, such as AlexNet and Grid Search optimization, while detecting and classifying
brain tumor MRI with CNN. Considering the rationale of [63,64] for the application of AI
in diagnostics, the proposed framework was broken down into many steps. The brain MRI
10 of 20
image was used as the primary input image. Data operations, including thresholding and
refractive error, were carried out to reduce noise. The database of brain MRI images was
analyzed and improved. The images were then resized for use as input to the model. A
A
VGG1616pre-trained
pre-trainedconvolution
convolutionlayer
layerwas
wasused
used to
to improve
improve and
VGG
and increase
increase classification
classification
accuracy
into
two
classes:
yes
and
no.
VGG
16
is
a
significantly
improved
accuracy into two classes: yes and no. VGG 16 is a significantly improved performance
performance
VGGNet
VGGNet variant
variant among
among the
the most
most advanced
advanced classification
classification networks.
networks. Figure
Figure 44 depicts
depicts the
the
structure of the proposed approach.
structure of the proposed approach.

Figure 4. Proposed Approach.
Figure 4. Proposed Approach.

4.1. Materials
Materials and
and Methods
Methods
4.1.
An automatic
automatic brain
brain tumor
tumor detection
detection and
and classification
classification method
method were
were implemented
implemented in
in
An
this
research
using
the
Faster
CNN
algorithm.
Faster
CNN
used
the
VGG
16
architecture
this research using the Faster CNN algorithm. Faster CNN used the VGG 16 architecture
as aa primary
primary network
network to
to generate
generate convolutional
convolutional feature
featuremaps,
maps,then
then classified
classifiedthese
theseto
to yield
yield
as
tumor region
region suggestions.
suggestions. Prediction
Prediction accuracy
accuracy was
wasused
usedto
toassess
assessperformance.
performance.
tumor
Todetect
detectbrain
brain tumors,
tumors, several
several researchers
researchers use development tools, such as MATLAB.
To
MATLAB.
However,the
theproposed
proposedresearch
researchwork
workopted
optedto
touse
use Python
Python programming
programming to
to complete
complete our
our
However,
projectobjective.
objective. Among
Among the
the reasons
reasonsthe
thepaper
paperchose
chosePython
Pythonare:
are:
project

  

Python
Python is
is free
free and
and open-source,
open-source, with
with more
more datasets
datasets and
and graphical
graphical packages
packages than
than
MATLAB
MATLAB[63].
[63].
   Python
much
more
precise
and accurate
than MATLAB
code. Python
Pythoncode
codeis is
much
more
precise
and accurate
than MATLAB
code.provides
Python
greater
control
over
implementation
to achieve and
better name
skills.
provides
greater
control
over implementation
to achieve
and visual-spatial
better name visual 
We
could
easily manage a variety of classic library versions.
spatial
skills.
 
We could easily manage a variety of classic library versions.
4.2. Data Pre-Processing and Dataset Division
4.2. Data
and Datasetthat
Division
Due Pre-Processing
to potential disturbances
are incurred while obtaining MRI machine boundaries,Due
MR images
may accrue
discrepancies,
suchincurred
as inhomogeneity
deformations
and the
to potential
disturbances
that are
while obtaining
MRI machine
heterogeneous
nature
of
the
movement.
These
artifacts
cause
false
intensity
rates
to be
boundaries, MR images may accrue discrepancies, such as inhomogeneity deformations
induced,
resulting
in
false-positive
results
in
the
image.
To
collaborate
with
these
artifacts,
and the heterogeneous nature of the movement. These artifacts cause false intensity rates
the
N4ITK
system
correctsinbias
field distortion.
to be
induced,
resulting
false-positive
results in the image. To collaborate with these
After
approaching
the
MRI
image,
pre-processing
artifacts, the N4ITK system corrects
biasafield
distortion. procedure was initially applied.
CNN struggles to adjust to the peculiarities of individual classifiers because the magnitude
in MR images have irregular black edges. Amplitude normalization was used to narrow
the intensity distribution to a normal range, culminating in a mean intensity value of zero
and a standard variance of one. To begin, the images were thresholder at 45 to remove
any minor patches of deformation, followed by a series of deprivations and dilations. The
photos were then normalized by gathering the most extensive contours of each image and
cutting the images on the contour s excess top, bottom, left, and right ends.

4.3. Dataset

Appl. Sci. 2022, 12, 7282

The dataset used to develop a respective framework in this study was  Brain MRI
Images for Brain Tumor Detection.  The employed dataset included three distinct and
well-known kinds of brain cancer: meningioma, glioma, and pituitary tumors. Sted
11 from
of 20
models were trained and tested using an MRI dataset that included 253 brain images
155 different patient features and cases. The data tumor dataset was submitted for
processing. Figure 5 depicts the structure of the Brain MRI Images dataset sample and
4.3.
Dataset process, as discussed below.
classification
The dataset used to develop a respective framework in this study was  Brain MRI
4.4. Image
andDetection. 
Classification
Images
for Processing
Brain Tumor
The employed dataset included three distinct and wellknown
kinds
of brain
cancer:
glioma,toand
pituitarythe
tumors.
Sted models
were
This
study
focused
on meningioma,
using convolution
eliminate
dark margins
from
the
trained
tested
using anonly
MRIthe
dataset
included
from 155 technique
different
imagesand
before
extracting
brainthat
region
from 253
MRIbrain
data.images
The detection
patient
features and strategy
cases. The
tumorthe
dataset
was
submitted
for processing.
Figure
5
was a multi-phase
fordata
detecting
edges
of objects
in images.
The edges
of the
depicts
the
structure
of
the
Brain
MRI
Images
dataset
sample
and
classification
process,
as
Real MRI brain have been shown using a clever edge detection algorithm, and then only
discussed
the brain below.
section of the image was trimmed.

Figure5.5.Brain
Brain MRI
MRI Images
Images Dataset
Dataset Sample
Sample (A)
Figure
(A) == image
imagewith
withdark
darkmargins,
margins,(B)
(B)==image
imagewithout
without
dark
margins).
dark margins).

Image
enhancement
boosts network performance by purposely creating more
4.4. Image
Processing
and Classification
training
data
from
original
input image
of the VGG
Network
hadfrom
a size
of
This study focused on data.
usingThe
convolution
to eliminate
the16dark
margins
the
224.
Thus,
the
training
dataset
was
used
to
resize
our
data
and
make
it
more
suitable
for
images before extracting only the brain region from MRI data. The detection technique was
process ofstrategy
classification.
It is a the
procedure
is used
throughout
DL toofaid
the
athe
multi-phase
for detecting
edges ofthat
objects
in images.
The edges
thein
Real
creation
of
samples.
It
also
optimizes
the
network s
efficiency
for
a
relatively
small
dataset.
MRI brain have been shown using a clever edge detection algorithm, and then only the
The images
addtrimmed.
variance to account for the dataset s small size. As a result,
brain
sectionwere
of thealtered
imageto
was
image
extensions
were used
to network
increase performance
the variability
our constrained
dataset
by
Image
enhancement
boosts
bywithin
purposely
creating more
training
collecting
Keras Image
Generator
6 depicts
different
types
of
data
from original
data. Data
The input
imagewhen
of thetraining.
VGG 16Figure
Network
had a size
of 224.
Thus,
the
brain
tumor
and
shows
the
classification
of
the
dataset
into
two
different
classes,
the training dataset was used to resize our data and make it more suitable for the process ofA
and B.
classification.
It is a procedure that is used throughout DL to aid in the creation of samples.
It also optimizes the network s efficiency for a relatively small dataset. The images were
altered to add variance to account for the dataset s small size. As a result, image extensions
were used to increase the variability within our constrained dataset by collecting Keras
Appl. Sci. 2022, 12, x FOR PEER REVIEW
12 of 20
Image Data Generator when training. Figure 6 depicts different types of the brain tumor
and shows the classification of the dataset into two different classes, A and B.

Figure6.6.Brain
Braintumor
tumortypes.
types.(A,B)
(A,B)==two
twodifferent
differentclasses
classesof
ofthe
thedataset.
dataset.
Figure

The entire augmentation process was as follows. The photos were shifted at random
angles ranging from 0 to 15 degrees (clockwise). These were shrunk to 10% of their
original size and shape. The visuals were arbitrarily boosted or dimmed from 0% to 50%.
The images were also sheared at an angle of 0.1 radians (counter-clockwise). Finally, the

Appl. Sci. 2022, 12, 7282

12 of 20

Figure 6. Brain tumor types. (A,B) = two different classes of the dataset.

The entire augmentation process was as follows. The photos were shifted at random
The entire augmentation process was as follows. The photos were shifted at random
angles ranging from 0 to 15 degrees (clockwise). These were shrunk to 10% of their
angles ranging from 0 to 15 degrees (clockwise). These were shrunk to 10% of their original
original size and shape. The visuals were arbitrarily boosted or dimmed from 0% to 50%.
size and shape. The visuals were arbitrarily boosted or dimmed from 0% to 50%. The
The images were also sheared at an angle of 0.1 radians (counter-clockwise). Finally, the
images were also sheared at an angle of 0.1 radians (counter-clockwise). Finally, the
photographs were randomly rotated horizontally and vertically.
photographs were randomly rotated horizontally and vertically.
4.5. Implementation
Implementation Details
Details
4.5.
ConvolutionalNeural
NeuralNetwork
Network(CNN)
(CNN)and
andVGG-16
VGG-16Network
NetworkFramework
Framework
Convolutional

  

CNN
CNN

As aa result
result of
of the
the hidden
hidden possibilities
possibilities of
of using
using the
the geometry
geometry of
of the
the images,
images, CNN s
CNN s
As
primary
applications
are
in
photo
editing.
In
graph
analysis,
CNN
outperforms
numerous
primary applications are in photo editing. In graph analysis, CNN outperforms numerous
techniques.Various
Various
architectural
concepts
are combined:
fields,
batch
techniques.
architectural
concepts
are combined:
receptivereceptive
fields, batch
normalizanormalization,
spatial orsub-sampling.
temporal sub-sampling.
Figurethe
7 depicts
theofstructure
of the
tion,
and spatialand
or temporal
Figure 7 depicts
structure
the suggested
suggested
CNN model.
CNN
model.

Figure 7. Flow Diagram of CNN Model.
Figure 7. Flow Diagram of CNN Model.

For tumor identification, a multi-layer convolutional neural network was constructed
For tumor identification,
a multi-layer
neural
was
constructed
and implemented.
An input shape
of 64  convolutional
64   3 was built
fornetwork
the MRI
scans
using a
and implemented.
input
shape
64   64   all
3 was
built
for the
MRI
scans using a
convolutional
layer An
as the
start
layer,ofconverting
of the
pictures
into
a homogeneous
dimension.
After
collecting
of the
images
in the same
we developed
a convolution
convolutional
layer
as the all
start
layer,
converting
all ofaspect,
the pictures
into a homogeneous
kernel
entangled
the input
Weimages
managed
size 3   3,a
dimension.
Afterwith
collecting
alllayer.
of the
in 32
theconvolutional
same aspect,filters
we of
developed
each
with thekernel
assistance
of 3 channel
tensors.
The cumulative
model,
which consisted
of
convolution
entangled
with the
input layer.
We managed
32 convolutional
filters
seven steps, including the hidden layers, produced the most precise result for malignant
concerns. ReLU did not relate to the output since it was used as an activation function.
ReLU could be stated mathematically as,
F(x) = max (0, x)

(1)

Processing the MRI image of the brain could lead to overfitting contaminants. We
used MaxPooling2D to generate spatial database models based on the input data. This
convolutional layer had size 31   31   32. The pool size was reduced due to splitting the
input photos in both spatial directions (2, 2).

(z) x =

aezi
 il aezi

(2)

The metrics used to analyze the study s outputs included specificity, sensitivity, fscore, and accuracy. These metric values were computed using the confusion matrix. As a

Appl. Sci. 2022, 12, 7282

13 of 20

consequence, the CNN model parameters were true positive (TP), true negative (TN), false
positive (FP), and false-negative (FN).
Accuracy (%) = (TP + TN)/(TP FP TN FN)

(3)

However, as previously stated, accuracy, sensitivity, or recall, as well as the F1-score
values, were also considered when examining the CNN performance of the model. These
metrics  equations are:
Precision (PPV) = TP/(TP FP)
(4)
Sensitivity = TP/(TP + FN)
F-score =

2(Percision   Recall)
Percion + Recall

TP + TN
TP FN FP TN
TP + TN
TP + FN
PYes =
 
TP + FN + FP + TN TP + FN + FP + TN
P0 =

PNo =

FP + TN
FN + TN
 
TP + FN + FP + TN TP + FN + FP + TN
Pe= PYes + PNo

 

(5)
(6)
(7)
(8)
(9)
(10)

Ensemble Classification

The Ensemble is a machine-learning method that provides numerous basic models to
generate an optimized predictive model. Many ensemble approaches have been identified
in the literature; however, the method with the highest number of votes was chosen
for this work. In most categorization situations, the majority technique was used. To
produce recommendations for each data point, this strategy employed numerous models.
Predictions for each model were taken into account. Most models  forecasts were used as
final predictions. The suggested technique employed a Convolutional Neural Network
(CNN) and a VGG 16 ensemble model. The characteristics were obtained from the VGG
16 s final fully-connected layer.
5. Results
The fundamental goal of our suggested study was to develop a well-fitting model,
while eliminating underfit and overfit issues. We concluded that our model did not induce
overfitting or underfitting. When comparing training and test data, the model loss should
be lower in training data. We discovered that deep learning systems, such as tensor flow
and Keras, were advantageous when using neural nets to solve classification tasks.
The benefit was that if we understand these fundamental notions and how effective
convolutional networks are, we can handle even the most challenging problems. Model
loss in training examples should be smaller than in test data. We found that deep learning
frameworks, such as tensor flow and Keras, were preferable when employing neural nets
to perform classification tasks. Convolutional networks could tackle the most challenging
problems if we comprehended these core concepts and the learning curve. These powerful
adjustment options could help us avoid fitting issues. The generalization difference was
the steeper learning curve gap between the training and test loss.
Accuracy = Number of correctly predicted images

(11)

Total number of images   100

(12)

5.1. Training and Validation Accuracy VGG-16
Accuracy and loss of the VGG 16 Model during training and validation were assessed.
Training indicated that AUC was not constant and became increasingly nonlinear as the

        
         ==       
         
            
                         
               
     
            
         
         
          100
100
Appl. Sci. 2022, 12, 7282

(11)
(11)
(12)
(12)

5.1.
5.1. Training
Training and
and Validation
Validation Accuracy
Accuracy VGG-16
VGG-16
14 of 20
Accuracy
and
loss
of
the
VGG
16
Model
during
training
and
validation
Accuracy and loss of the VGG 16 Model during training and validation were
were
assessed.
assessed. Training
Training indicated
indicated that
that AUC
AUC was
was not
not constant
constant and
and became
became increasingly
increasingly
nonlinear
as the
of
increased.
The
of
in
nonlinear
the number
number
of repetitions
repetitions
increased.
Theinvalidation
validation
of AUC
AUCunchanged
in VGG
VGG 16
16
number ofas
repetitions
increased.
The validation
of AUC
VGG 16 remained
at
remained
unchanged
at
98.15%.
We
employed
two
classes
and
evaluated
the
accuracy
of
remained
unchanged
at
98.15%.
We
employed
two
classes
and
evaluated
the
accuracy
of
98.15%. We employed two classes and evaluated the accuracy of using the above approach.
using
the
approach.
Our model
achieved
an f1
of 92.6%
with
aa recall
of
using
the above
above
approach.
model
achieved
f1 score
score
92.6%Our
withsystem
recallimproved
of 94.4%.
94.4%.
Our model
achieved
an f1Our
score
of 92.6%
withan
a recall
ofof
94.4%.
Our
system
improved
when
the
number
of
trained
images
and
hyper-parameters
Our
improved
whenimages
the number
of trained images
and hyper-parameters
whensystem
the number
of trained
and hyper-parameters
increased.
Figures 8 and 9
increased.
Figures 88 and
9 present
training
and validation
loss
of
VGG
training
increased.
present the
the
training
loss
of validation
VGG 16,
16, and
and
training
present theFigures
training and
and 9validation
loss
of VGGand
16, validation
and training
and
accuracy
of
and
validation
accuracy
of
VGG
16,
respectively.
and
accuracy of VGG 16, respectively.
VGGvalidation
16, respectively.

Figure
VGG-16.
Figure 8.
8. Training
Training and
and Validation
Validation Loss
Figure
8.
Training
and
Validation
Loss VGG-16.

Figure 9.
9. Training
Training And
And Validation
Validation Accuracy
Accuracy VGG-16.
VGG-16.
Figure
Figure 9. Training And Validation Accuracy VGG-16.

5.2. Training and Validation Accuracy CNN
5.2.
Training and
Accuracy
CNN
5.2.
and Validation
Validation
Accuracy
CNN
The training
indicated
that recollection
was inconsistent and very nonlinear
a
Appl. Sci. 2022, 12, x FOR PEER REVIEW Training
15 as
of 20
The
training
indicated
that
recollection
was inconsistent
and
very
as aa
The training
indicated
recollection
and accuracy
very nonlinear
nonlinear
repetitions
approach.
Figuresthat
10 and
11 presentwas
the inconsistent
training loss and
of CNNas
and
repetitions
approach.
Figures
10
and
11
the
repetitions
approach.
Figures
10 of
and
11 present
present
the training
training loss
loss and
and accuracy
accuracy of
of CNN
CNN
training and
validation
accuracy
CNN,
respectively.
and
training
and
validation
accuracy
of
CNN,
respectively.
and training and validation accuracy of CNN, respectively.

Figure 10. Training
Training Loss and Accuracy CNN.

Appl. Sci. 2022, 12, 7282

15 of 20

Figure 10. Training Loss and Accuracy CNN.

Figure11.
11.Training
Trainingand
andValidation
ValidationAccuracy
AccuracyCNN.
CNN.
Figure

Accordingtotothe
thetraining,
training,
the
recall
metrics
measurement
nearly
reached
a change
According
the
recall
metrics
measurement
nearly
reached
a change
in
in
iteration
and
remained
virtually
constant
as
the
number
of
iterations
increased.
The
iteration and remained virtually constant as the number of iterations increased. The
generalizationdifference
differencewas
wasthe
thesteeper
steeperlearning
learningcurve
curvegap
gapbetween
betweenthe
thetrain
trainand
andtest
test
generalization
loss.
The
advantage
is
that
if
we
comprehend
the
core
concepts
and
the
learning
curve,
loss. The advantage is that if we comprehend the core concepts and the learning curve,
convolutional networks could tackle the most challenging problems. These powerful
convolutional networks could tackle the most challenging problems. These powerful
adjustment options could help us avoid fitting issues.
adjustment options could help us avoid fitting issues.
5.3. Ensemble Model: Validation and Training

5.3. Ensemble Model: Validation and Training

Compared to VGG 16, which obtained a training and testing accuracy of 98.15% and
Compared
to VGG
16, which
obtained
a training
and atesting
accuracy
of 98.15%
and
recall
of 97%, the
suggested
ensemble
model
achieved
training
and testing
accuracy
recall
of
97%,
the
suggested
ensemble
model
achieved
a
training
and
testing
accuracy
Appl. Sci. 2022, 12, x FOR PEER REVIEW
16 ofof
20
of 98.41% with an F1-score of 91.52% and recall of 91%. Compared to loss performance
98.41%
with
an
F1-score
of
91.52%
and
recall
of
91%.
Compared
to
loss
performance
metrics and ensembles, the model testing loss was too low at roughly 2.01 correspondingly.
metrics
ensembles,
the and
model
testing
loss was
low at
roughly 2.01
Figure 12and
presents
the training
valuation
accuracy
of thetoo
ensemble
model.
correspondingly. Figure 12 presents the training and valuation accuracy of the ensemble
model.

Figure12.
12. Training
Training and
and Validation
Validation Accuracy
Accuracy Ensemble
Ensemble Model.
Model.
Figure

5.4. Result Analysis and Discussion
5.4. Result Analysis and Discussion
We ran our tests on a PC running the Linux 4.0.0 LTS platform with a Geforce R.T.X.
We ran our tests on a PC running the Linux 4.0.0 LTS platform with a Geforce R.T.X.
2080Ti GPU. On an Intel Xeon-2620, Core i5-2.4GHz CPU, and 16 GB RAM, the CNN VGG
2080Ti GPU. On an Intel Xeon-2620, Core i5-2.4GHz CPU, and 16 GB RAM, the CNN VGG
16 and Ensembles models were verified using Python in the Keras module. The CNN, VGG
16 and Ensembles models were verified using Python in the Keras module. The CNN,
16, 80% data was reserved for training, 10% for validation, and the other 10% for testing, a
VGG
16, rate
80%of
data
wasover
reserved
for training,
10%offor
andcross-entropy
the other 10%
learning
0.0001
80 epochs,
a batch size
16,validation,
and category
as for
the
testing,
a
learning
rate
of
0.0001
over
80
epochs,
a
batch
size
of
16,
and
category
crosserror rate were used to train the Network.
entropy
the error framework
rate were used
to trainCNN,
the Network.
Ourassuggested
comprised
VGG 1, and Ensemble, respectively, with
Our suggested
CNN,
VGG
and Ensemble,
respectively,
reasonable
accuracy framework
achieved viacomprised
CNN at 96%,
VGG
16 at1,98.5%,
and Ensemble
Model at
with
reasonable
accuracy
achieved
via
CNN
at
96%,
VGG
16
at
98.5%,
and
Ensemble
98.14%, as described in Table 2.
Model at 98.14%, as described in Table 2.
Table 2. Performance and Result of Proposed Approach.
Models
CNN
VGG-16
Ensemble Model

Accuracy
96%
98.15%
98.41%

Recall
89.5%
94.4%
91.4%

F1-Score Validation_Accuracy
91.76%
87.34%
92.6%
98.01%
91.54%
91.29%

Test_Accuracy
89.5%
97.6%
91.29%

Appl. Sci. 2022, 12, 7282

16 of 20

Table 2. Performance and Result of Proposed Approach.
Models

Accuracy

Recall

F1-Score

Validation_Accuracy

Test_Accuracy

CNN
VGG-16
Ensemble
Model

96%
98.15%

89.5%
94.4%

91.76%
92.6%

87.34%
98.01%

89.5%
97.6%

98.41%

91.4%

91.54%

91.29%

91.29%

6. Discussion
As seen in the preceding research investigation, the acquired accuracies for brain
MRI classification using deep learning approaches are much higher than those obtained
using classical ML techniques. On the other hand, deep learning algorithms require
enormous quantities of data for training to surpass traditional methods. According to recent
studies, deep learning approaches have obviously crossed the threshold of specialized and
intelligent systems and computer vision. Furthermore, the approaches have limits that
should be considered when working with brain tumor diagnosis and classification. So, in
Table 1, our proposed solution was compared, in terms of performance, with the previous
research to show how improved performance could be achieved with the integration of deep
learning and transfer learning models. Comparison with past literature established the need
for this study, while arguing for higher performance achieved through implementation.
This study made an attempt to meet such needs by bringing a novel solution for the
detection of brain tumors in MRI images with greater precision. The proposed model
integrated deep learning and transfer learning models to achieve a remarkable accuracy
rate. As compared to similar techniques from past literature, in this study, the optimization
of training models was increased to reduce the need for high computational power.
Early diagnosis and suitable viable treatments are essential to adequately treat brain
tumor diseases. Alternative treatments are defined by tumor stage, pathological type of
disease, and tumor stage at the initial diagnosis. The study results gained in this research
were contrasted to state-of-the-art approaches in the base tumor detection challenge or
standard deep learning-based techniques that have been offered. Conventional recognition
systems use some fundamental machine-learning-oriented methodologies that collect
only low- and high-level characteristics in the early phases of critical extracting features.
Therefore, Table 2 shows how the suggested hybrid design outperformed approaches in
all brain tumor types and categories. The suggested method was particularly effective for
the central and boosting regions and improved tumor detection cells, resulting in high
sensitivity estimates for the respective areas. The proposed model had an accuracy of
89%, which could be enhanced using other techniques. Implementing image processing
techniques and evaluating other AI techniques  effectiveness could achieve the same results.
Soon, several organizations and business models are to be proposed to assist radiologists
and physicians in the quick and adaptable detection of brain tumors using AI.
The essential variables stated for the proposed model demonstrated that it was efficient
in finding original tumor areas, while avoiding false positives. Most current approaches
concentrate on the entire tumor region, resulting in poor performance measurements
for core and augment regions, emphasizing the importance of the design developed in
this study. The methods presented in the literature should include statistical and deep
learning-based methodologies, with CNN excelling at dealing with task complexity. Due
to the clinical importance of the tumor detection problem, time constraints, sensitivity,
and effectiveness are essential. The results validated the efficiency and efficacy of the
proposed approaches, especially in terms of fundamental and augmenting regions and
specific values, where it outperformed previous methods by a wide margin.
7. Conclusions
The diagnosis of brain tumors is essential in clinical treatments. It is critical to interpret
medical images because medical images vary greatly. The automatic brain tumor detection
approach makes detection easier, but it also significantly increases the patient s chances

Appl. Sci. 2022, 12, 7282

17 of 20

of survival. Convolutional networks for brain tumor categorization have helped pave the
way for better tumor detection and accuracy. MRI is most commonly used to detect and
classify brain cancers. Due to the apparent efficient feature extraction capacity of DL-based
techniques, they have recently gained greater attention and efficiency when compared
to standard classification techniques for medical imaging. If cancer is diagnosed, many
lives can be spared, and the appropriate grade is determined using quick and low-cost
diagnostic tools. As a result, there is an urgent need to create rapid, non-invasive, and
cost-effective diagnostic tools. This study made an attempt to meet such needs by bringing
a novel solution for the detection of brain tumors in MRI images with greater precision.
The proposed model integrated deep learning and transfer learning models to achieve
a remarkable accuracy rate. As compared to similar techniques from past literature, in
this study, the optimization of training models was increased to reduce the need for high
computational power.
In this study, a CNN was built to detect brain tumors using MRI scans of the brain
automatically. The network could be trained for faster and more convenient training using
a pre-trained VGG 16 model. VGG 16 has sixteen layers and is a critical CNN model to
evaluate if employing a commercial model for a task. This paper aimed to discover a brain
tumor using the VGG 16, CNN model architecture, and weights to training data. The
precision of the outcome was evaluated. Brain MRI images for tumor identification are
the type of data we aimed to acquire for our study. Compared to conventional methods,
the results showed that the proposed network architecture was appealing and performed
exceptionally well in detecting tumors. Various processing operations were also carried
out to enhance the model s efficiency.
The proposed approach for brain tumor diagnosis was based on deep learning, and
brain magnetic resonance was used for tumor evaluation using automated classification
methods. For image improvement and better classification, a CNN model was used in this
paper. The study successfully yielded better outcomes while requiring less computing time.
Our method was used to identify brain tumors in MR images. The algorithm significantly
outperformed previously studies. The methodologies used for detecting brain tumors in
the testing data (Precision = 96%, 98.15%, 98.41%, and F1-score = 91.78%, 92.6%, and 91.29%)
achieved high accuracy of CNN 96%, VGG 16 98.5%, and Ensemble Model is 98.14%. The
reliability of the validation and learning was discovered to be increasing, and the findings
higher. They could be utilized to diagnose the existence of a tumor in the brain.
The limitation of the research lies in its exclusive focus on brain tumors that can be
extended to account for different types of cancer attacks in MRI images. Future research
can make use of a variety of image modalities and diverse segmentation techniques to
acquire the best approximation of affected regions in the brain to isolate these regions from
unaffected parts of the brain. Different modalities having image registration distinctions
from each other could be utilized for presenting the missing image features in the fixed
image and conducting the best classification. To achieve higher precision and accuracy,
ensembles could be further used.
Author Contributions: Conceptualization, C.O.N.; Data curation, A.Y. and M.J.A.; Formal analysis,
A.Y., L.Q. and M.J.A.; Funding acquisition, L.Q.; Investigation, A.Y., L.Q., C.O.N. and M.J.A.; Methodology, A.Y.; Project administration, A.Y. and H.B.K.; Resources, C.O.N.; Software, A.Y.; Supervision,
L.Q. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the National Natural Science Foundation of China under
Grant No.61471263 and No.61872267, the Natural Science Foundation of Tianjin, China, under Grant
16JCZDJC31100, and Tianjin University Innovation Foundation under Grant 2021XZC-0024.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: Not applicable.
Conflicts of Interest: The authors declare no conflict of interest.

Appl. Sci. 2022, 12, 7282

18 of 20

References
1.
2.
3.
4.

5.
6.
7.
8.
9.
10.
11.
12.

13.
14.
15.
16.

17.
18.

19.
20.
21.
22.
23.
24.
25.
26.
27.

Anitha, V.; Murugavalli, S. Brain tumor classification using two-tier classifier with adaptive segmentation technique. IET Comput.
Vis. 2016, 10, 9 11. [CrossRef]
Badillo, S.; Banfai, B.; Birzele, F.; Davydov, I.I.; Hutchinson, L.; Kam-Thong, T.; Siebourg-Polster, J.; Steiert, B.; Zhang, J.D. An
introduction to machine learning. Clin. Pharmacol. Ther. 2020, 107, 871 885. [CrossRef] [PubMed]
Patil, R.B.; Ansingkar, N.; Deshmukh, P.D. Deep Learning Based Brain Tumor Segmentation: Recent Updates. In Rising Threats in
Expert Applications and Solutions; Springer: Singapore, 2022; pp. 395 405.
Menze, B.H.; Jakab, A.; Bauer, S.; Kalpathy-Cramer, J.; Farahani, K.; Kirby, J.; Burren, Y.; Porz, N.; Slotboom, J.; Wiest, R.; et al. The
multimodal brain tumor image segmentation benchmark (BRATS). IEEE Trans. Med. Imaging 2015, 34, 1993 2024. [CrossRef]
[PubMed]
Yaqub, M.; Feng, J.; Zia, M.S.; Arshid, K.; Jia, K.; Rehman, Z.U.; Mehmood, A. State-of-the-art CNN optimizer for brain tumor
segmentation in magnetic resonance images. Brain Sci. 2020, 10, 427. [CrossRef]
Amin, J.; Sharif, M.; Yasmin, M.; Fernandes, S.L. A distinctive approach in brain tumor detection and classification using M.R.I.
Pattern Recognit. Lett. 2020, 139, 118 127. [CrossRef]
Ellor, S.V.; Pagano-Young, T.A.; Avgeropoulos, N.G. Glioblastoma: Background, standard treatment paradigms, and supportive
care considerations. J. Law Med. Ethics 2014, 42, 171 182. [CrossRef]
Beers, A.; Chang, K.; Brown, J.; Sartor, E.; Mammen, C.P.; Gerstner, E.; Rosen, B.; Kalpathy-Cramer, J. Sequential 3D U-nets for
biologically-informed brain tumor segmentation. arXiv 2017, 1709, 02967.
Goodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; M.I.T. Press: Cambridge, MA, USA, 2016.
Tamm, M.O.; Muhammad, Y.; Muhammad, N. Classification of vowels from imagined speech with convolutional neural networks.
Computers 2020, 9, 46. [CrossRef]
Cecotti, H.; Graeser, A. Convolutional neural network with embedded Fourier transform for E.E.G. classification. In Proceedings
of the 19th International Conference on Pattern Recognition, Tampa, FL, USA, 8 11 December 2008; pp. 1 14.
Kamnitsas, K.; Ledig, C.; Newcombe, V.F.J.; Simpson, J.P.; Kane, A.D.; Menon, D.K.; Rueckert, D.; Glocker, B. Efficient multiscale
3D CNN with fully connected C.R.F. for accurate brain lesion segmentation. Med. Image Anal. 2017, 36, 61 78. [CrossRef]
[PubMed]
Popuri, K.; Cobzas, D.; Murtha, A.; J gersand, M. 3D variational brain tumor segmentation using Dirichlet priors on a clustered
feature set. Int. J. Comput. Assist. Radiol. Surg. 2012, 7, 493 506. [CrossRef] [PubMed]
Kwon, D.; Akbari, H.; Da, X.; Gaonkar, B.; Davatzikos, C. Multimodal brain tumor image segmentation using GLISTR. In
Proceedings of the BRATS-MICCAI (2014), Boston, MA, USA, 14 September 2014; pp. 18 19.
Jia, H.; Xia, Y.; Song, Y.; Cai, W.; Fulham, M.; Feng, D.D. Atlas registration and ensemble deep convolutional neural network-based
prostate segmentation using magnetic resonance imaging. Neurocomputing 2018, 275, 1358 1369. [CrossRef]
Parisot, S.; Duffau, H.; Chemouny, S.; Paragios, N. Joint tumor segmentation and dense deformable registration of brain
M.R. images. In Proceedings of the International Conference on Medical Image Computing and Computer, Nice, France,
1 5 October 2012.
Jiang, Y.; Zhang, Y.; Lin, X.; Dong, J.; Cheng, T.; Liang, J. SwinBTS: A Method for 3D Multimodal Brain Tumor Segmentation
Using Swin Transformer. Brain Sci. 2022, 12, 797. [PubMed]
Hussain, S.; Anwar, S.M.; Muhammad, M. Brain tumor segmentation using cascaded deep convolutional neural Network. In
Proceedings of the 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),
Jeju, Korea, 11 15 July 2017; pp. 1998 2001.
Athency, A.; Ancy, B.M.; Fathima, K.; Dilin, R.; Binish, M. Brain Tumor Detection and Classification in M.R.I. Images. Int. J. Innov.
Res. Sci. Eng. Technol. 2017, 6, 84 89.
Mohsen, H.; El-Dahshan, E.S.A.; El-Horbaty, E.S.M.; Salem, A.B.M. Classification using deep learning neural networks for brain
tumors. Futur. Comput. Inform. J. 2018, 3, 68 71. [CrossRef]
Kachwalla, M.; Shinde, M.P.; Katare, R.; Agrawal, A.; Wadhai, V.M.; Jadhav, M.S. Classification of Brain M.R.I. Images For Cancer
Detection Using Deep Learning. Int. J. Adv. Res. Comput. Commun. Eng. 2017, 3, 635 637.
Chattopadhyay, A.; Maitra, M. MRI-based Brain Tumor Image Detection Using CNN based Deep Learning Method. Neuroscience
Informatics 2022, 2, 100060.
Deepak, S.; Ameer, P.M. Brain tumor classification using deep CNN features via transfer learning. Comput. Biol. Med. 2019, 111,
103345. [CrossRef]
Raj, A.; Anil, A.; Deepa, P.L.; Aravind Sarma, H.; Naveen Chandran, R. BrainNET: A Deep Learning Network for Brain Tumor
Detection and Classification. In Advances in Communication Systems and Networks; Springer: Singapore, 2020; pp. 577 589.
Anilkumar, B.; Kumar, P.R. Tumor classification using block wise fine tuning and transfer learning of deep neural network and
K.N.N. classifier on M.R. brain images. Int. J. Emerg. Trends Eng. Res. 2020, 8, 574 583.
Begum, S.S.; Lakshmi, D.R. Combining optimal wavelet statistical texture and recurrent neural Network for tumor detection and
classification over MRI. Multimed. Tools Appl. 2020, 79, 14009 14030. [CrossRef]
Boustani, A.E.; Aatila, M.; Bachari, E.E.; Oirrak, A.E. MRI brain images classification using convolutional neural networks. In
Proceedings of the Advanced Intelligent Systems for Sustainable Development, Marrakech, Morocco, 8 11 July 2019; Springer:
Cham, Switzerland, 2019.

Appl. Sci. 2022, 12, 7282

28.
29.
30.

31.
32.
33.
34.

35.
36.
37.
38.
39.
40.
41.
42.
43.
44.
45.
46.
47.
48.

49.
50.
51.

52.
53.
54.
55.

19 of 20

Maharjan, S.; Alsadoon, A.; Prasad, P.W.C.; Al-Dalain, T.; Alsadoon, O.H.A. novel enhanced s ftmax loss function for brain tumor
detection using deep learning. J. Neurosci. Methods 2020, 330, 108520. [CrossRef] [PubMed]
DeAngelis, L.M. Brain tumors. N. Engl. J. Med. 2001, 344, 114 123. [CrossRef]
Bangalore Yogananda, C.G.; Das, Y.; Wagner, B.C.; Nalawade, S.S.; Reddy, D.; Holcomb, J.; Pinho, M.C.; Fei, B.; Madhuranthakam,
A.J.; Maldjian, J.A. Disparity Autoencoders for Multi-class Brain Tumor Segmentation. In International MICCAI Brainlesion
Workshop; Springer: Cham, Switzerland, 2022; pp. 116 124.
Urban, G.; Bendszus, M.; Hamprecht, F.; Kleesiek, J. Multi-modal brain tumor segmentation using deep convolutional neural
networks. In Proceedings of the BRATS-MICCAI 2014, Boston, MA, USA, 14 September 2014.
Al-Araj, R.S.A.; Abed, S.K.; Al-Ghoul, A.N.; Abu-Naser, S.S. Classification of Animal Species Using Neural Network. Int. J. Acad.
Eng. Res. 2020, 4, 23 31.
Soomro, T.A.; Zheng, L.; Afifi, A.J.; Ali, A.; Soomro, S.; Yin, M.; Gao, J. Image Segmentation for MR Brain Tumor Detection Using
Machine Learning: A Review. IEEE Rev. Biomed. Eng. 2022. [CrossRef] [PubMed]
Yeo, M.; Tahayori, B.; Kok, H.K.; Maingard, J.; Kutaiba, N.; Russell, J.; Thijs, V.; Jhamb, A.; Chandra, R.V.; Brooks, M.; et al. Review
of deep learning algorithms for the automatic detection of intracranial hemorrhages on computed tomography head imaging. J.
Neurointerv. Surg. 2021, 13, 369 378. [CrossRef] [PubMed]
More, S.S.; Mange, M.A.; Sankhe, M.S.; Sahu, S.S. Convolutional Neural Network Based Brain Tumor Detection. In Proceedings
of the 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), Madurai, India  6 8 May 2021.
More, R.B.; Bhisikar, S. Brain tumor detection using deep neural network. In Techno-Societal 2020; Springer: Berlin/Heidelberg,
Germany, 2021; pp. 85 94.
Woz niak, M.; Si ka, J.; Wieczorek, M. Neural Computing and Applications Deep neural network correlation learning mechanism
for CT brain tumor detection. Neural Comput. Appl. 2021, 1 16. [CrossRef]
Samadi, F.; Akbarizadeh, G.; Kaabi, H. Change Detection in S.A.R. Images using Deep Belief Network: A New Training Approach
based on Morphological Images. I.E.T. Image Process. 2019, 13, 2255 2264. [CrossRef]
LeCun, Y.; Kavukcuoglu, K.; Farabet, C. Convolutional networks and applications in vision. In Proceedings of the 2010 IEEE
International Symposium on Circuits and Systems, Paris, France, 30 May 2 June 2010; pp. 253 256.
Bauer, S.; Wiest, R.; Nolte, L.-P.; Reyes, M. A survey of MRI-based medical image analysis for brain tumor studies. Phys. Med. Biol.
2013, 58, 97. [CrossRef]
Sajid, S.; Hussain, S.; Sarwar, A. Brain Tumor Detection and Segmentation in M.R. Images Using Deep Learning. Arab. J. Sci. Eng.
2019, 4, 9249 9261. [CrossRef]
Zhao, X.; Yihong, W.; Song, G.; Li, Z.; Zhang, Y.; Fan, Y. A deep learning model integrating FCNNs and C.R.F.s for brain tumor
segmentation. Med. Image Anal. 2018, 43, 98 111. [CrossRef]
Tharani, S.; Yamini, C. Yamini Classification using convolutional neural Network for heart and diabetics. Int. J. Adv. Res. Comp.
Commun. Eng. 2016, 5, 417e22.
Litjens, G.; Kooi, T.; Bejnordi, B.E.; Setio, A.A.A.; Ciompi, F.; Ghafoorian, M.; S nchez, C.I. A survey on deep learning in medical
image analysis. Med Image Anal. 2017, 42, 60 88. [CrossRef] [PubMed]
Anuse, A.; Vyas, V. A novel training algorithm for convolutional neural Network. Complex Intell. Syst. 2016, 2, 221 234. [CrossRef]
Elzamly, A.; Hussin, B.; Abu-Naser, S.S.; Doheir, M. Classification of Software Risks with Discriminant Analysis Techniques in
Software planning Development Process. Int. J. Adv. Sci. Technol. 2015, 81, 35 48. [CrossRef]
Santos, D.; Santos, E. Brain tumor detection using deep learning. medRxiv 2022. [CrossRef]
El Boustani, A.; El Bachari, E.M.R.I. Brain Images Compression and Classification Using Different Classes of Neural Networks. In
Proceedings of the International Conference on Model and Data Engineering, Toulouse, France, 28 31 October 2019; Springer:
Berlin/Heidelberg, Germany, 2019; pp. 122 134.
Kalaiselvi, T.; Padmapriya, S.T.; Sriramakrishnan, P.; Somasundaram, K. Deriving tumor detection models using convolutional
neural networks from M.R.I. of human brain scans. Int. J. Inf. Technol. 2020, 12, 403 408.
Huang, Z.; Lin, L.; Cheng, P.; Peng, L.; Tang, X. Multi-modal Brain Tumor Segmentation via Missing Modality Synthesis and
Modality-level Attention Fusion. arXiv 2022, arXiv:2203.04586.
Vimal Kurup, R.; Sowmya, V.; Soman, K.P. Effect of Data Pre-processing on Brain Tum r Classification Using Capsulenet. In
Proceedings of the International Conference on Intelligent Computing and Communication Technologies, Hyderabad, India, 9 11
January 2019; Springer: Berlin/Heidelberg, Germany, 2020.
Mukherkjee, D.; Saha, P.; Kaplun, D.; Sinitca, A.; Sarkar, R. Brain tumor image generation using an aggregation of GAN models
with style transfer. Sci. Rep. 2022, 12, 9141.
Siar, M.; Teshnehlab, M. Brain tumor detection using deep neu al network and machine learning algorithm. In Proceedings of the
2019 9th International Conference on Computer and Knowledge Engineering (ICCKE), Mashhad, Iran, 24 25 October 2019.
Ari, A.; Hanbay, D. Deep learning based brain tumor classification and detection system. Turk. J. Electr. Eng. Comput. Sci. 2018,
26, 2275 2286. [CrossRef]
Joshi, S.R.; Headley, D.B.; Ho, K.C.; Par , D.; Nair, S.S. Classification of brainwaves using convolutional neural network. In
Proceedings of the 2019 27th European Signal Processing Conference (EUSIPCO), A Coru a, Spain, 2 6 September 2019; pp. 1 5.

Appl. Sci. 2022, 12, 7282

56.

57.

58.
59.
60.

61.
62.
63.

64.

20 of 20

Krishnammal, P.M.; Raja, S.S. Convolutional neural network based image classification and detection of abnormalities in
M.R.I. brain images. In Proceedings of the 2019 International Conference on Communication and Signal Processing (ICCSP),
Melmaruvathur, Tamil Nadu, India, 4 6 April 2019.
Poonguzhali, N.; Rajendra, K.R.; Mageswari, T.; Pavithra, T. Heterogeneous deep neural network or healthcare using metric
learning. In Proceedings of the 2019 IEEE International Conference on System, Computation, Automation and Networking
(ICSCAN), Pondicherry, India, 29 30 March 2019.
Sharif, M.I.; Li, J.P.; Khan, M.A.; Saleem, M.A. Active deep neural network features selection for segmentation and recognition of
brain tumors using M.R.I. images. Pattern Recognit. Lett. 2020, 129, 181 189. [CrossRef]
Pandian, A.A.; Balasubramanian, R. Fusion of contourlet transform and zernike moments using content based image retrieval for
M.R.I. brain tumor images. Indian J. Sci. Technol. 2016, 9, 1 8. [CrossRef]
Pan, Y.; Huang, W.; Lin, Z.; Zhu, W.; Zhou, J.; Wong, J.; Ding, Z. Brain tumor grading based on neural networks and convolutional
neural networks. In Proceedings of the 2015 37th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Milan, Italy, 25 29 August 2015.
Han, C.; Rundo, L.; Araki, R.; Nagano, Y.; Furukawa, Y.; Mauri, G.; Nakayama, H.; Hayashi, H. Combining noise-to-image and
image-to-image GANs: Brain MR image augmentation for tumor detection. arXiv 2019, arXiv:1905.13456. [CrossRef]
Sambasivam, G.; Opiyo, G.D. A predictive machine learning application in agriculture: Cassava disease detection and classification with imbalanced dataset using convolutional neural networks. Egypt. Inform. J. 2021, 22, 27 34. [CrossRef]
Devi, R.L. Detection and Automated Classification of Brain Tumor Types in MRI Images using Convolutional Neural Network
with Grid Search Optimization. In Proceedings of the 2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile,
Analytics and Cloud) (I-SMAC), Palladam, India, 11 13 November 2021; IEEE: Piscataway, NJ, USA, 1963; pp. 1280 1284.
Akinbolajo, O.S. Evaluating Neural Network Methods for Brain Hemorrhage Identification and Classification from Computed
Tomography Imagery. Doctoral Dissertation, Texas A&M University-Kingsville, Kingsville, TX, USA, 2020.

